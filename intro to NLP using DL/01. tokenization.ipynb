{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52f45c6",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "- 의미를 잃어버리지 않는 선에서 정제작업 진행\n",
    "- 교착어의 특성 상, 한국어는 띄어쓰기만으로 토큰 구별 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72fce5",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14887056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', \"n't\", 'know', 'how', 'to', 'draw', 'anything', 'except', 'boa', 'constrictors', 'from', 'the', 'outside', 'and', 'boa', 'constrictors', 'from', 'the', 'inside']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(\"I don't know how to draw anything except boa constrictors from the outside and boa constrictors from the inside\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5c282",
   "metadata": {},
   "source": [
    "- 'don't'을 'do'와 \"n't\"로 분리하는 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b76599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'don', \"'\", 't', 'know', 'how', 'to', 'draw', 'anything', 'except', 'boa', 'constrictors', 'from', 'the', 'outside', 'and', 'boa', 'constrictors', 'from', 'the', 'inside']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "print(WordPunctTokenizer().tokenize(\"I don't know how to draw anything except boa constrictors from the outside and boa constrictors from the inside\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd8fb4",
   "metadata": {},
   "source": [
    "- 'don't'을 'don', \" ' \", 't'로 분리하는 것을 확인할 수 있음\n",
    "- 구두점을 별도로 분류함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c308e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"don't\", 'know', 'how', 'to', 'draw', 'anything', 'except', 'boa', 'constrictors', 'from', 'the', 'outside', 'and', 'boa', 'constrictors', 'from', 'the', 'inside']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "print(text_to_word_sequence(\"I don't know how to draw anything except boa constrictors from the outside and boa constrictors from the inside\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b98d4",
   "metadata": {},
   "source": [
    "- 'don't'을 그대로 보존함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c8a9b",
   "metadata": {},
   "source": [
    "##### 고려사항\n",
    "- 마침표, 문장 부호는 문장의 성격을 대변할 수 있음\n",
    "    - 밥 먹었어? 밥 먹었어.\n",
    "- 단어 사이에 띄어쓰기가 있어도 한 단어로 보아야 하는 경우가 있음\n",
    "    - New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ee38d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', \"n't\", 'know', 'how', 'to', 'draw', 'anything', 'except', 'boa', 'constrictors', 'from', 'the', 'outside', 'and', 'boa', 'constrictors', 'from', 'the', 'inside']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "text = \"I don't know how to draw anything except boa constrictors from the outside and boa constrictors from the inside\"\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e66cc3",
   "metadata": {},
   "source": [
    "- 'don't'을 'do'와 \"n't\"로 분리하는 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f0a3c",
   "metadata": {},
   "source": [
    "### Sentence Tokenization\n",
    "- 문장을 어떻게 나눌 것인가?\n",
    "- 마침표를 기준으로??\n",
    "    - 마침표가 들어가는 다른 단어를 고려해야 함 \"Ph.D.\", \"Washington, D.C.\"\n",
    "    - 따라서 코퍼스 내에서 어떻게 사용되고 있는지 규칙 정의하는 것이 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d988429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I pondered deeply, then, over the adventures of the jungle.', 'And after some work with a colored pencil Isucceeded in making my first drawing.', 'My Drawing Number One.', 'It looked something like this.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"I pondered deeply, then, over the adventures of the jungle. And after some work with a colored pencil Isucceeded in making my first drawing. My Drawing Number One. It looked something like this.\"\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e965e",
   "metadata": {},
   "source": [
    "### POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c51b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0058dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('pondered', 'VBD'), ('deeply', 'RB'), (',', ','), ('then', 'RB'), (',', ','), ('over', 'IN'), ('the', 'DT'), ('adventures', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('jungle', 'NN'), ('.', '.'), ('And', 'CC'), ('after', 'IN'), ('some', 'DT'), ('work', 'NN'), ('with', 'IN'), ('a', 'DT'), ('colored', 'JJ'), ('pencil', 'NN'), ('Isucceeded', 'NNP'), ('in', 'IN'), ('making', 'VBG'), ('my', 'PRP$'), ('first', 'JJ'), ('drawing', 'NN'), ('.', '.'), ('My', 'PRP$'), ('Drawing', 'VBG'), ('Number', 'NNP'), ('One', 'NNP'), ('.', '.'), ('It', 'PRP'), ('looked', 'VBD'), ('something', 'NN'), ('like', 'IN'), ('this', 'DT'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "print(pos_tag(tokenized_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
